import streamlit as st
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler
import joblib
import re
from urllib.parse import urlparse
import socket
import os

st.title(" AI ê¸°ë°˜ í”¼ì‹± íƒì§€ ì‹œìŠ¤í…œ ")
st.write("ê³ ë„í™”ëœ AI ëª¨ë¸ë¡œ ì‹¤ì œ URLì˜ í”¼ì‹± ì—¬ë¶€ë¥¼ ì •í™•í•˜ê²Œ ë¶„ì„í•©ë‹ˆë‹¤!")

# URL íŠ¹ì„± ì¶”ì¶œ í•¨ìˆ˜ë“¤
def extract_url_features(url):
    """URLì—ì„œ í”¼ì‹± íƒì§€ë¥¼ ìœ„í•œ íŠ¹ì„±ë“¤ì„ ì¶”ì¶œ"""
    try:
        # URL íŒŒì‹±
        parsed_url = urlparse(url if url.startswith(('http://', 'https://')) else 'http://' + url)
        domain = parsed_url.netloc.lower()
        path = parsed_url.path
        
        features = {}
        
        # ê¸°ë³¸ íŠ¹ì„±ë“¤
        features['url_length'] = len(url)
        features['domain_length'] = len(domain)
        features['num_dots'] = url.count('.')
        features['num_hyphens'] = url.count('-')
        
        # ì¶”ê°€ íŠ¹ì„±ë“¤
        features['has_https'] = 1 if url.startswith('https://') else 0
        features['num_subdomains'] = len(domain.split('.')) - 2 if len(domain.split('.')) > 2 else 0
        features['has_suspicious_words'] = 1 if any(word in url.lower() for word in 
                                                  ['secure', 'account', 'update', 'confirm', 'verify', 'login']) else 0
        features['num_digits'] = len(re.findall(r'\d', url))
        features['num_params'] = len(parsed_url.query.split('&')) if parsed_url.query else 0
        features['path_length'] = len(path)
        features['has_ip'] = 1 if re.match(r'^\d+\.\d+\.\d+\.\d+', domain) else 0
        
        # ë„ë©”ì¸ ì˜ì‹¬ë„ ì²´í¬
        suspicious_tlds = ['.tk', '.ml', '.ga', '.cf', '.click', '.download']
        features['suspicious_tld'] = 1 if any(url.lower().endswith(tld) for tld in suspicious_tlds) else 0
        
        return features, None
        
    except Exception as e:
        return None, str(e)

def check_domain_reputation(domain):
    """ë„ë©”ì¸ í‰íŒ ê°„ë‹¨ ì²´í¬"""
    try:
        socket.gethostbyname(domain)
        return " ë„ë©”ì¸ì´ ì¡´ì¬í•©ë‹ˆë‹¤"
    except:
        return " ë„ë©”ì¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"

# í†µí•©ëœ í”¼ì‹± íƒì§€ ì‹œìŠ¤í…œ í´ë˜ìŠ¤
class UnifiedPhishingDetectionSystem:
    def __init__(self):
        self.model = None
        self.scaler = None
        self.feature_names = ['url_length', 'domain_length', 'num_dots', 'num_hyphens', 
                            'has_https', 'num_subdomains', 'has_suspicious_words', 
                            'num_digits', 'num_params', 'path_length', 'has_ip', 'suspicious_tld']
        self.model_loaded = False
    
    def load_external_model(self, model_path='phishing_detector.pkl'):
        """ì™¸ë¶€ì—ì„œ ìƒì„±ëœ ê³ ê¸‰ ëª¨ë¸ ë¡œë“œ"""
        try:
            if os.path.exists(model_path):
                model_data = joblib.load(model_path)
                if isinstance(model_data, dict):
                    # ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ì €ì¥ëœ ê²½ìš°
                    self.model = model_data.get('model')
                    self.scaler = model_data.get('scaler')
                    if model_data.get('feature_columns'):
                        self.feature_names = model_data['feature_columns']
                else:
                    # ëª¨ë¸ë§Œ ì €ì¥ëœ ê²½ìš°
                    self.model = model_data
                
                self.model_loaded = True
                return True, "ê³ ê¸‰ ì™¸ë¶€ ëª¨ë¸"
        except Exception as e:
            st.warning(f"ì™¸ë¶€ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        return False, None
    
    def create_enhanced_sample_data(self):
        """í–¥ìƒëœ ìƒ˜í”Œ ë°ì´í„° ìƒì„±"""
        np.random.seed(42)
        data = []
        
        # ì •ìƒ URL ë°ì´í„° (1500ê°œ)
        for i in range(1500):
            data.append({
                'url_length': np.random.randint(10, 50),
                'domain_length': np.random.randint(5, 20),
                'num_dots': np.random.randint(1, 3),
                'num_hyphens': np.random.randint(0, 2),
                'has_https': np.random.choice([0, 1], p=[0.1, 0.9]),  # 90% HTTPS
                'num_subdomains': np.random.randint(0, 2),
                'has_suspicious_words': np.random.choice([0, 1], p=[0.9, 0.1]),  # 10% ì˜ì‹¬ ë‹¨ì–´
                'num_digits': np.random.randint(0, 3),
                'num_params': np.random.randint(0, 2),
                'path_length': np.random.randint(0, 20),
                'has_ip': 0,  # ì •ìƒ ì‚¬ì´íŠ¸ëŠ” IP ì£¼ì†Œ ì‚¬ìš© ì•ˆí•¨
                'suspicious_tld': 0,  # ì •ìƒ ì‚¬ì´íŠ¸ëŠ” ì˜ì‹¬ìŠ¤ëŸ¬ìš´ TLD ì‚¬ìš© ì•ˆí•¨
                'label': 0  # ì •ìƒ
            })
        
        # í”¼ì‹± URL ë°ì´í„° (1500ê°œ)
        for i in range(1500):
            data.append({
                'url_length': np.random.randint(50, 150),
                'domain_length': np.random.randint(20, 60),
                'num_dots': np.random.randint(3, 8),
                'num_hyphens': np.random.randint(2, 10),
                'has_https': np.random.choice([0, 1], p=[0.4, 0.6]),  # 60% HTTPS
                'num_subdomains': np.random.randint(2, 6),
                'has_suspicious_words': np.random.choice([0, 1], p=[0.2, 0.8]),  # 80% ì˜ì‹¬ ë‹¨ì–´
                'num_digits': np.random.randint(3, 15),
                'num_params': np.random.randint(2, 8),
                'path_length': np.random.randint(15, 80),
                'has_ip': np.random.choice([0, 1], p=[0.7, 0.3]),  # 30% IP ì‚¬ìš©
                'suspicious_tld': np.random.choice([0, 1], p=[0.6, 0.4]),  # 40% ì˜ì‹¬ TLD
                'label': 1  # í”¼ì‹±
            })
        
        return pd.DataFrame(data)
    
    def train_fallback_model(self):
        """ì™¸ë¶€ ëª¨ë¸ì´ ì—†ì„ ê²½ìš° ì‚¬ìš©í•  í´ë°± ëª¨ë¸ í•™ìŠµ"""
        df = self.create_enhanced_sample_data()
        
        X = df[self.feature_names]
        y = df['label']
        
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ì´ˆê¸°í™”
        self.scaler = StandardScaler()
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # ë” ê°•ë ¥í•œ ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸
        self.model = RandomForestClassifier(
            n_estimators=300, 
            max_depth=15,
            min_samples_split=3,
            min_samples_leaf=2,
            random_state=42
        )
        self.model.fit(X_train_scaled, y_train)
        
        y_pred = self.model.predict(X_test_scaled)
        accuracy = accuracy_score(y_test, y_pred)
        
        return accuracy
    
    def predict_from_features(self, features):
        """íŠ¹ì„±ìœ¼ë¡œë¶€í„° ì˜ˆì¸¡"""
        if self.model is None:
            return None
        
        # ëª¨ë“  íŠ¹ì„±ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ëˆ„ë½ëœ ê²ƒì€ 0ìœ¼ë¡œ ì±„ì›€
        feature_vector = []
        for feature_name in self.feature_names:
            feature_vector.append(features.get(feature_name, 0))
        
        input_data = np.array([feature_vector])
        
        # ìŠ¤ì¼€ì¼ë§ ì ìš© (ìŠ¤ì¼€ì¼ëŸ¬ê°€ ìˆëŠ” ê²½ìš°)
        if self.scaler is not None:
            input_data = self.scaler.transform(input_data)
        
        prediction = self.model.predict(input_data)[0]
        probabilities = self.model.predict_proba(input_data)[0]
        
        return {
            'prediction': 'Phishing' if prediction == 1 else 'Legitimate',
            'phishing_probability': probabilities[1] if len(probabilities) > 1 else (1 - probabilities[0]),
            'confidence': max(probabilities)
        }
    
    def get_feature_importance(self):
        """íŠ¹ì„± ì¤‘ìš”ë„ ë°˜í™˜"""
        if self.model is None or not hasattr(self.model, 'feature_importances_'):
            return None
        
        importance = self.model.feature_importances_
        return dict(zip(self.feature_names, importance))

# ì‹œìŠ¤í…œ ì´ˆê¸°í™”
@st.cache_resource
def initialize_system():
    system = UnifiedPhishingDetectionSystem()
    
    # 1. ë¨¼ì € ì™¸ë¶€ ê³ ê¸‰ ëª¨ë¸ ë¡œë“œ ì‹œë„
    success, model_type = system.load_external_model('phishing_detector.pkl')
    
    if success:
        st.success(f"{model_type} ë¡œë“œ ì™„ë£Œ!")
        return system, model_type
    else:
        # 2. ì™¸ë¶€ ëª¨ë¸ì´ ì—†ìœ¼ë©´ í´ë°± ëª¨ë¸ í•™ìŠµ
        with st.spinner("ë‚´ì¥ ê³ ì„±ëŠ¥ ëª¨ë¸ì„ í•™ìŠµì¤‘ì…ë‹ˆë‹¤... (ì•½ 5ì´ˆ ì†Œìš”)"):
            try:
                accuracy = system.train_fallback_model()
                st.success(f"ë‚´ì¥ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ! ì •í™•ë„: {accuracy:.2%}")
                return system, "ë‚´ì¥ ê³ ì„±ëŠ¥ ëª¨ë¸"
            except Exception as e:
                st.error(f"âŒ ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                return None, None

# ì‹œìŠ¤í…œ ì´ˆê¸°í™”
if 'system' not in st.session_state:
    system, model_type = initialize_system()
    st.session_state.system = system
    st.session_state.model_type = model_type
else:
    system = st.session_state.system
    model_type = st.session_state.model_type

if system:
    # ë©”ì¸ ì¸í„°í˜ì´ìŠ¤
    st.header("ğŸŒ ì‹¤ì‹œê°„ URL í”¼ì‹± íƒì§€")
    
    # URL ì…ë ¥
    url_input = st.text_input(
        "URLì„ ì…ë ¥í•˜ì„¸ìš”:",
        placeholder="ì˜ˆ: https://www.google.com ë˜ëŠ” suspicious-site.com",
        help="http:// ë˜ëŠ” https://ë¥¼ í¬í•¨í•˜ì—¬ ì…ë ¥í•˜ê±°ë‚˜, ë„ë©”ì¸ë§Œ ì…ë ¥í•´ë„ ë©ë‹ˆë‹¤."
    )
    
    # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ë²„íŠ¼ë“¤
    st.subheader("ë¹ ë¥¸ í…ŒìŠ¤íŠ¸")
    col1, col2, col3, col4 = st.columns(4)
    
    test_urls = {
        "ì •ìƒ ì‚¬ì´íŠ¸": "https://www.google.com",
        "ì˜ì‹¬ ì‚¬ì´íŠ¸ 1": "http://secure-bank-verify-account-12345.suspicious-domain.tk/login?confirm=true&urgent=yes",
        "ì˜ì‹¬ ì‚¬ì´íŠ¸ 2": "https://192.168.1.100/paypal-security-update-urgent-verify-now.html?user=12345",
        "ì˜ì‹¬ ì‚¬ì´íŠ¸ 3": "http://www-amazon-security-update-confirm-account.verify-login-details.ml/secure/update"
    }
    
    for i, (label, url) in enumerate(test_urls.items()):
        col = [col1, col2, col3, col4][i]
        with col:
            if st.button(label, key=f"test_{i}"):
                st.session_state.selected_url = url
                st.rerun()
    
    # ì„ íƒëœ URL ì²˜ë¦¬
    if 'selected_url' in st.session_state:
        url_input = st.session_state.selected_url
        st.info(f"ì„ íƒëœ URL: {url_input}")
    
    # URL ë¶„ì„ ì‹¤í–‰
    if url_input and st.button("URL ë¶„ì„ ì‹¤í–‰", type="primary"):
        with st.spinner("AIê°€ URLì„ ë¶„ì„ì¤‘ì…ë‹ˆë‹¤..."):
            # URL íŠ¹ì„± ì¶”ì¶œ
            features, error = extract_url_features(url_input)
            
            if error:
                st.error(f"URL ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {error}")
            else:
                # ë„ë©”ì¸ í‰íŒ ì²´í¬
                parsed_url = urlparse(url_input if url_input.startswith(('http://', 'https://')) else 'http://' + url_input)
                domain_status = check_domain_reputation(parsed_url.netloc)
                
                # ì˜ˆì¸¡ ìˆ˜í–‰
                result = system.predict_from_features(features)
                
                if result:
                    st.subheader(f" ë¶„ì„ ê²°ê³¼")
                    
                    # ë©”ì¸ ê²°ê³¼ í‘œì‹œ
                    if result['prediction'] == 'Phishing':
                        st.error(" **í”¼ì‹± ì‚¬ì´íŠ¸ë¡œ ì˜ì‹¬ë©ë‹ˆë‹¤!**")
                        st.error(f"**í”¼ì‹± í™•ë¥ : {result['phishing_probability']:.1%}**")
                        st.warning("ì´ ì‚¬ì´íŠ¸ì— ê°œì¸ì •ë³´ë¥¼ ì…ë ¥í•˜ì§€ ë§ˆì„¸ìš”!")
                    else:
                        st.success(" **ë¹„êµì  ì•ˆì „í•œ ì‚¬ì´íŠ¸ì…ë‹ˆë‹¤.**")
                        st.success(f"**ì•ˆì „ í™•ë¥ : {1-result['phishing_probability']:.1%}**")
                    
                    # ì¶”ê°€ ì •ë³´
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("ì‹ ë¢°ë„", f"{result['confidence']:.1%}")
                    with col2:
                        st.info(f"ğŸŒ {domain_status}")
                    
                    # ìœ„í—˜ ìš”ì†Œ ë¶„ì„
                    risk_factors = []
                    if features['url_length'] > 75:
                        risk_factors.append(f"âš ï¸ URLì´ ë§¤ìš° ê¹ë‹ˆë‹¤ ({features['url_length']}ì)")
                    if features['domain_length'] > 30:
                        risk_factors.append(f"âš ï¸ ë„ë©”ì¸ì´ ë¹„ì •ìƒì ìœ¼ë¡œ ê¹ë‹ˆë‹¤ ({features['domain_length']}ì)") 
                    if features['num_dots'] > 5:
                        risk_factors.append(f"âš ï¸ ì„œë¸Œë„ë©”ì¸ì´ ë§ìŠµë‹ˆë‹¤ (ì  {features['num_dots']}ê°œ)")
                    if features['num_hyphens'] > 4:
                        risk_factors.append(f"âš ï¸ í•˜ì´í”ˆì´ ë§ìŠµë‹ˆë‹¤ ({features['num_hyphens']}ê°œ)")
                    if features['has_https'] == 0:
                        risk_factors.append("âš ï¸ HTTPSë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
                    if features['has_suspicious_words'] == 1:
                        risk_factors.append("âš ï¸ ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ë‹¨ì–´ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤")
                    if features['has_ip'] == 1:
                        risk_factors.append("âš ï¸ IP ì£¼ì†Œë¥¼ ì§ì ‘ ì‚¬ìš©í•©ë‹ˆë‹¤")
                    if features['suspicious_tld'] == 1:
                        risk_factors.append("âš ï¸ ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ìµœìƒìœ„ ë„ë©”ì¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤") 
                    
                    if risk_factors:
                        st.subheader("ğŸš¨ ë°œê²¬ëœ ìœ„í—˜ ìš”ì†Œ")
                        for factor in risk_factors:
                            st.write(f"â€¢ {factor}")
                    else:
                        st.success("âœ… **íŠ¹ë³„í•œ ìœ„í—˜ ìš”ì†Œê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.**")
                    
                    # ìƒì„¸ íŠ¹ì„± ì •ë³´ (ì ‘ì„ ìˆ˜ ìˆëŠ” í˜•íƒœ)
                    with st.expander("ğŸ” ìƒì„¸ ë¶„ì„ ì •ë³´"):
                        feature_df = pd.DataFrame([
                            {"íŠ¹ì„±": "URL ê¸¸ì´", "ê°’": features['url_length']},
                            {"íŠ¹ì„±": "ë„ë©”ì¸ ê¸¸ì´", "ê°’": features['domain_length']},
                            {"íŠ¹ì„±": "ì (.) ê°œìˆ˜", "ê°’": features['num_dots']},
                            {"íŠ¹ì„±": "í•˜ì´í”ˆ(-) ê°œìˆ˜", "ê°’": features['num_hyphens']},
                            {"íŠ¹ì„±": "HTTPS ì‚¬ìš©", "ê°’": "ì˜ˆ" if features['has_https'] else "ì•„ë‹ˆì˜¤"},
                            {"íŠ¹ì„±": "ì„œë¸Œë„ë©”ì¸ ê°œìˆ˜", "ê°’": features['num_subdomains']},
                            {"íŠ¹ì„±": "ì˜ì‹¬ ë‹¨ì–´ í¬í•¨", "ê°’": "ì˜ˆ" if features['has_suspicious_words'] else "ì•„ë‹ˆì˜¤"},
                            {"íŠ¹ì„±": "ìˆ«ì ê°œìˆ˜", "ê°’": features['num_digits']},
                            {"íŠ¹ì„±": "ë§¤ê°œë³€ìˆ˜ ê°œìˆ˜", "ê°’": features['num_params']},
                            {"íŠ¹ì„±": "ê²½ë¡œ ê¸¸ì´", "ê°’": features['path_length']},
                            {"íŠ¹ì„±": "IP ì£¼ì†Œ ì‚¬ìš©", "ê°’": "ì˜ˆ" if features['has_ip'] else "ì•„ë‹ˆì˜¤"},
                            {"íŠ¹ì„±": "ì˜ì‹¬ìŠ¤ëŸ¬ìš´ TLD", "ê°’": "ì˜ˆ" if features['suspicious_tld'] else "ì•„ë‹ˆì˜¤"}
                        ])
                        st.dataframe(feature_df, use_container_width=True, hide_index=True)

    # ì‚¬ì´ë“œë°” - ì‹œìŠ¤í…œ ì •ë³´
    st.sidebar.title("ğŸ¤– ì‹œìŠ¤í…œ ì •ë³´")
    st.sidebar.success(f"**í™œì„± ëª¨ë¸**: {model_type}")
    
    if system:
        importance = system.get_feature_importance()
        if importance:
            st.sidebar.write("### ğŸ¯ ì£¼ìš” íƒì§€ íŠ¹ì„±")
            sorted_importance = sorted(importance.items(), key=lambda x: x[1], reverse=True)[:5]
            for feature, imp in sorted_importance:
                st.sidebar.write(f"**{feature}**: {imp:.3f}")
    
    st.sidebar.markdown("---")
    st.sidebar.markdown("""
    ### í”¼ì‹± íƒì§€ ê°€ì´ë“œ
    
    **ìœ„í—˜ ì‹ í˜¸:**
    - ë§¤ìš° ê¸´ URL (75ì ì´ìƒ)
    - ë§ì€ í•˜ì´í”ˆê³¼ ì 
    - IP ì£¼ì†Œ ì§ì ‘ ì‚¬ìš©
    - 'secure', 'verify' ë“± ê¸‰ë°•í•¨ì„ ì¡°ì„±í•˜ëŠ” ë‹¨ì–´
    - ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ë„ë©”ì¸ (.tk, .ml ë“±)
    
    **ì•ˆì „ ì‹ í˜¸:**
    - HTTPS ì‚¬ìš©
    - ì§§ê³  ë‹¨ìˆœí•œ ë„ë©”ì¸
    - ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ìµœìƒìœ„ ë„ë©”ì¸
    
    ### ì£¼ì˜ì‚¬í•­
    ì´ ë„êµ¬ëŠ” ì°¸ê³ ìš©ì…ë‹ˆë‹¤. ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì‚¬ì´íŠ¸ì—ëŠ” ê°œì¸ì •ë³´ë¥¼ ì…ë ¥í•˜ì§€ ë§ˆì„¸ìš”.
    """)

else:
    st.error("âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•´ì£¼ì„¸ìš”.")

# í‘¸í„°
st.markdown("---")
st.markdown("ğŸ›¡ï¸ **AI í”¼ì‹± íƒì§€ ì‹œìŠ¤í…œ v4** | ê³ ë„í™”ëœ AIë¡œ ë”ìš± ì •í™•í•œ í”¼ì‹± íƒì§€")